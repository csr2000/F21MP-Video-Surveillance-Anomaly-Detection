{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1402cdf",
   "metadata": {},
   "source": [
    "# VIDEO SURVEILLANCE ANOMALY DETECTION-H00390442\n",
    "\n",
    "Thesis submission in fulfilment of the requirements for the degree of MSc. Artificial Intelligence. \n"
   ]
  },
  {
   "attachments": {
    "Flow%20diagram.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "57df71e7",
   "metadata": {},
   "source": [
    "Video surveillance for crime prevention plays a vital role in public safety and security due to the high increase in crimes.  With the advent of new AI algorithms, new automatic detection methods have proved to be useful and these systems are trained to detect fires, raising alerts, identifying unattended baggage etc. in real-time. \n",
    "\n",
    "In this project, we compare and contrast different combination of models that uses Convolutional Neural Networks such as GoogLeNet, ResNet and Vision Transformers in a Transfer Learning approach using UCF Crime Dataset. The model will be evaluated based on measures such as accuracy and AUC curve.\n",
    "\n",
    "The diagram below gives the steps involved to achieve the goal of the project. \n",
    "\n",
    "![Flow%20diagram.png](attachment:Flow%20diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d4cb9",
   "metadata": {},
   "source": [
    "### The following cell is run for Vision Transformers and had to be placed before import commands to avoid error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68ebe86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt -qq install git-lfs\n",
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb3481a",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d51605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import cv2\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization, MaxPooling2D, GlobalAvgPool2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1fd5d",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition\n",
    "\n",
    "The dataset is downloaded from https://www.dropbox.com/sh/75v5ehq4cdg5g5g/AABvnJSwZI7zXb8_myBA0CLHa?dl=0 given in   https://www.crcv.ucf.edu/projects/real-world/ which consists of 13 folders of anomaly videos and one folder of normal videos. The dataset which consists of zip folders was downloaded and extracted.  \n",
    "\n",
    "As we are focussing specifically on spatial features, we need to extract the frames from the videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52a38a",
   "metadata": {},
   "source": [
    "## Step 2: Extract Video Frames\n",
    "\n",
    "\n",
    "Following the documentation of opencv given in https://docs.opencv.org/4.x/dd/d43/tutorial_py_video_display.html, we extract the frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset was saved in an external harddisk due to the large size. Path to dataset in the system is given below \n",
    "root_dir=r\"E:\\DATASETS\\UCF Crime\\UCF Crime\"\n",
    "\n",
    "count = 0\n",
    "videoFile = mainPath\n",
    "cap = cv2.VideoCapture(root_dir)   # capturing the video from the given path\n",
    "frameRate = cap.get(10) #frame rate\n",
    "x=1\n",
    "for dir in os.listdir(root_dir):\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1) #current frame number\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if (ret != True):\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            filename =\"frame%d.png\" % count;\n",
    "            count+=1\n",
    "            cv2.imwrite(filename, frame)\n",
    "# When everything done, release the capture\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c5b21",
   "metadata": {},
   "source": [
    "Count the number of images extracted for each of the anomalies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941095ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abuse': 19076,\n",
       " 'Arrest': 26397,\n",
       " 'Arson': 24421,\n",
       " 'Assault': 10360,\n",
       " 'Burglary': 39504,\n",
       " 'Explosion': 18753,\n",
       " 'Fighting': 24684,\n",
       " 'NormalVideos': 413920,\n",
       " 'Robbery': 41493,\n",
       " 'Shooting': 7140,\n",
       " 'Shoplifting': 24835,\n",
       " 'Stealing': 44802,\n",
       " 'Vandalism': 13626,\n",
       " 'RoadAccidents': 23486}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Categories={}\n",
    "for dir in os.listdir(root_dir):\n",
    "    Categories[dir]=len(os.listdir(os.path.join(root_dir,dir)))\n",
    "\n",
    "Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494a6cd",
   "metadata": {},
   "source": [
    "## Step 3: Splitting images to 80% train and 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22da5144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Folder exists\n"
     ]
    }
   ],
   "source": [
    "#Creating Training folder\n",
    "\n",
    "if not os.path.exists(\"./train\"):\n",
    "    os.mkdir(\"./train\")\n",
    "    \n",
    "    for dir in os.listdir(root_dir):\n",
    "        os.makedirs(\"./train/\"+dir)\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)),size=(math.floor(80/100*Categories[dir])-5), replace=False):\n",
    "            O=os.path.join(root_dir,dir,img)\n",
    "            D=os.path.join(\"./train\",dir)\n",
    "            shutil.copy(O,D)\n",
    "            os.remove(O)\n",
    "            \n",
    "else:\n",
    "    print(\"Train Folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17498917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Folder exists\n"
     ]
    }
   ],
   "source": [
    "#Creating Test folder\n",
    "\n",
    "if not os.path.exists(\"./test\"):\n",
    "    os.mkdir(\"./test\")\n",
    "    \n",
    "    for dir in os.listdir(root_dir):\n",
    "        os.makedirs(\"./test/\"+dir)\n",
    "        for img in np.random.choice(a=os.listdir(os.path.join(root_dir,dir)),size=(math.floor(20/100*Categories[dir])-5), replace=False):\n",
    "            O=os.path.join(root_dir,dir,img)\n",
    "            D=os.path.join(\"./test\",dir)\n",
    "            shutil.copy(O,D)\n",
    "            os.remove(O)\n",
    "            \n",
    "else:\n",
    "    print(\"Test Folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956179da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"E:\\DATASETS\\UCF Crime\\Train\"\n",
    "test_dir = r\"E:\\DATASETS\\UCF Crime\\Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaee3cd",
   "metadata": {},
   "source": [
    "## Step 4: Data Pre-processing using data generator\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d360b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing using data generator\n",
    "train_datagen=image.ImageDataGenerator(zoom_range=0.2, shear_range=0.2, rescale=1./255, horizontal_flip=True)\n",
    "test_Datagen=image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1675178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 732497 images belonging to 14 classes.\n",
      "Found 111308 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "#Flow from directory: Loading data in terms of batches\n",
    "\n",
    "train_data=train_datagen.flow_from_directory(directory=train_dir,target_size=(256,256), batch_size=64,color_mode = \"rgb\",class_mode='categorical')\n",
    "test_data=test_Datagen.flow_from_directory(directory=test_dir,target_size=(256,256), batch_size=64,color_mode = \"rgb\",class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6887b",
   "metadata": {},
   "source": [
    "## Step 5: ResNet50 Model\n",
    "\n",
    "Following the Keras documentation available from the following sites\n",
    "\n",
    "https://keras.io/api/applications/resnet/#resnet50-function\n",
    "\n",
    "https://keras.io/guides/transfer_learning/, \n",
    "\n",
    "we build our model by transfering the weights of ImageNet dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e314bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Resnet_model=Sequential()\n",
    "pretrained_model=tf.keras.applications.ResNet50(include_top=False,weights=\"imagenet\",input_shape=(256,256,3),classes=14)\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable=False\n",
    "Resnet_model.add(pretrained_model)\n",
    "Resnet_model.add(Flatten())\n",
    "Resnet_model.add(Dense(14,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2d83b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 14)                1835022   \n",
      "=================================================================\n",
      "Total params: 25,422,734\n",
      "Trainable params: 1,835,022\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Resnet_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])\n",
    "Resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e506183",
   "metadata": {},
   "source": [
    "Having early stopping and model check point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7936c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping\n",
    "es = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n",
    "# model check point\n",
    "mc = ModelCheckpoint(filepath=\"resnet_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "# puting call back in a list \n",
    "call_back = [es, mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1090de",
   "metadata": {},
   "source": [
    "### Experimentation of ResNet Model\n",
    "\n",
    "The model was trained only on one epoch and later on five epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55a0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11446/11446 [==============================] - ETA: 0s - loss: 2.2121 - accuracy: 0.6738 - auc: 0.9081\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43614, saving model to resnet_model.h5\n",
      "11446/11446 [==============================] - 115791s 10s/step - loss: 2.2121 - accuracy: 0.6738 - auc: 0.9081 - val_loss: 3.5313 - val_accuracy: 0.4361 - val_auc: 0.8068\n"
     ]
    }
   ],
   "source": [
    "hist=Resnet_model.fit(x=train_data,validation_data=test_data, epochs=1, callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b45eeb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 2.2041 - accuracy: 0.6742 - auc: 0.9084\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.35243, saving model to resnet_model.h5\n",
      "11446/11446 [==============================] - 123075s 11s/step - loss: 2.2041 - accuracy: 0.6742 - auc: 0.9084 - val_loss: 6.6845 - val_accuracy: 0.3524 - val_auc: 0.7507\n",
      "Epoch 2/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 1.6085 - accuracy: 0.7511 - auc: 0.9356\n",
      "Epoch 00002: val_accuracy did not improve from 0.35243\n",
      "11446/11446 [==============================] - 121217s 11s/step - loss: 1.6085 - accuracy: 0.7511 - auc: 0.9356 - val_loss: 5.5417 - val_accuracy: 0.3222 - val_auc: 0.7341\n",
      "Epoch 3/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 1.4199 - accuracy: 0.7808 - auc: 0.9440\n",
      "Epoch 00003: val_accuracy did not improve from 0.35243\n",
      "11446/11446 [==============================] - 123020s 11s/step - loss: 1.4199 - accuracy: 0.7808 - auc: 0.9440 - val_loss: 6.5811 - val_accuracy: 0.3227 - val_auc: 0.7429\n",
      "Epoch 4/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 1.3283 - accuracy: 0.7970 - auc: 0.9477\n",
      "Epoch 00004: val_accuracy improved from 0.35243 to 0.39277, saving model to resnet_model.h5\n",
      "11446/11446 [==============================] - 121916s 11s/step - loss: 1.3283 - accuracy: 0.7970 - auc: 0.9477 - val_loss: 5.4911 - val_accuracy: 0.3928 - val_auc: 0.7735\n",
      "Epoch 5/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 1.2717 - accuracy: 0.8094 - auc: 0.9513\n",
      "Epoch 00005: val_accuracy did not improve from 0.39277\n",
      "11446/11446 [==============================] - 121134s 11s/step - loss: 1.2717 - accuracy: 0.8094 - auc: 0.9513 - val_loss: 7.1658 - val_accuracy: 0.2791 - val_auc: 0.6594\n"
     ]
    }
   ],
   "source": [
    "hist=Resnet_model.fit(x=train_data,validation_data=test_data, epochs=5, callbacks=call_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3491d28",
   "metadata": {},
   "source": [
    "### Loading the best fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1e0a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"resnet_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0869ec0",
   "metadata": {},
   "source": [
    "### ResNet Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85b5c675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-eebd3e4a9878>:1: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "1740/1740 [==============================] - 14646s 8s/step - loss: 5.4911 - accuracy: 0.3928 - auc: 0.7735\n",
      "The accuracy of Resnet50 model is =39.27749991416931%\n"
     ]
    }
   ],
   "source": [
    "acc=model.evaluate_generator(generator=test_data,steps=len(test_data),verbose=1)[1]\n",
    "print(f\"The accuracy of Resnet50 model is ={acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d3595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'auc', 'val_loss', 'val_accuracy', 'val_auc'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=hist.history\n",
    "h.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab34bd8",
   "metadata": {},
   "source": [
    "### ResNet model plot against training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1fa2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3ZklEQVR4nO3deXhU5fXA8e/JThLWBMISJIBsIhoI4oJLcGlxxQUqWFG0arFS61LXn1WqtZu2tbZaq1StrRoFi6LFDQpFq60s4sKmCAiIIjtZCNnO74/3Jkwmk2QSczND5nyeZ57M3c/cmdxz7/u+972iqhhjjIldcZEOwBhjTGRZIjDGmBhnicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4ngICMir4rIpS09r4lOIjJFRN4OGC4SkX7hzNuMbdnvJUZZImgF3j9v9atKRPYFDH+3KetS1dNV9a8tPW9ziEhf7/M87Nc2DnYi0ktEKkSkf4hps0Xk/qasT1XTVXVdC8Q1XUT+HrRuv38v00VERWSUX9swzWOJoBV4/7zpqpoObATODhj3dPV8IpIQuSib5RJgFzBRRJJbc8MiEt+a22suVf0CmA9MDhwvIl2AMwDfDrzRREQEtw92Aq161XEQ/l+1OksEESQi+SKyWURuEZGvgCdEpLOIvCIi20Rkl/c+O2CZhSJyhfd+ioi8LSL3e/OuF5HTmzlvXxFZJCKFIjJPRB4KPmMM4RLgDqAcODvos40TkeUisldEPhORsd74LiLyhIhs8eJ4MTC+oHWoiBzqvX9SRP4kInNFpBgYIyJnisj73jY2icj0oOWPF5F3RGS3N32KiBwlIlsDDw4icoGILA/x/RwjIl8FJh0ROU9EPvTejxKRJd72t4rIb+vZT38lKBEAE4EVqvqRiNzq7aNCEVkpIufVs57gfZIhInO87b8H9A+a9/fe594rIktF5ARv/FjgduBC76r0A2984O8lTkTuEJHPReRrEXlKRDp603K8OC4VkY0isl1E/q++mD0nAD2BH+FOHJIC4mwnIr/xtrXH+52286bV+Q6DY/WGg4vQVESuEZFPgU8b2h/etHgRuT3ge1gqIr29/4PfBO3Xl0XkukY+78FFVe3Vii9gA3Cq9z4fqAB+BSQD7YAM4AIgFWgPzAReDFh+IXCF934K7iB8JRAPXA1sAaQZ874L3A8kAccDe4G/N/A5TgD2A52BPwBzAqaNAvYAp+FONnoBg71p/wSe85ZLBE4KiO/toG0ocKj3/klvnaO9daZ4+2+YN3wEsBU415v/EKAQmORtJwPI9aatBE4P2M5s4MZ6PudnwGkBwzOBWwP22WTvfTpwTD3raOfFfnzAuHeB67z3E3AHyTjgQqAY6BFqvwTtkwLgeSANOBz4Imjei73PnQDcCHwFpHjTpgd/v0G/l8uBtUA/77P9A/ibNy3Hi+Mx77Md6f0WhjTwe/mLF2sisAM4P2DaQ962e+F+m8fh/h8a+g5rYm1gP70JdAHahbE/bgI+AgYB4n2mDNxveQsQ582XCZQAWZE+lrTocSnSAcTai7qJoKz6x1jP/LnAroDhwH/WKcDagGmp3j9A96bM6/3DVQCpAdP/HnygCIprBl6CAo7FJZlu3vCfgd+FWKYHUAV0DjGt1j+yNy44ETzVyL59oHq7wG3A7HrmuwV42nvfxfvH7lHPvD8DHvfet8cdpPt4w4uAnwKZYXzvM4BHvfcDvO+9Wz3zLgfGhdov1fsEd8Asx0uw3rSfB+/DoPXuAo703k8P/n6Dfi/zgR8ETBvkbS+BA4kgO2D6e8DEerabijuxODfg9/GS9z4O2FcdV9ByDX2HNbE2sJ9ObuQ7Cdwfa6r3eYj5VuGdDADTgLmNfd8H28uKhiJvm6qWVg+ISKqI/Nm7TN6LO9h0kvrLxL+qfqOqJd7b9CbO2xPYGTAOYFN9AXuX7ROAp711vYur+7jIm6U37kw6WG9vO7vqW3cjasUkIkeLyAJxxWh7gKm4M7aGYgCX5M4WkXTgO8BbqvplPfM+A5wvrg7kfGCZqn7uTfseMBBYLSKLReSsBmL/K/AdEUnBFRO9pqpfe5/jEnHFaLtFZDfu7D6z/lUB0BV3UA7cJ58HziAiN4rIKq+4ZTfQMYz1VusZtL7Pve1lBYz7KuB9CfX/7s7DnWjM9YafBk4Xka5ePCnU/3up7zsMR/DvpaH90dC2/oq7msD7+7dvEFNUskQQecHdv96IO/s6WlU7ACd648XHGL4EuohIasC43g3Mfx7QAXjYK0P/CndZf4k3fRNB5dUB47uISKcQ04pxZ44AiEj3EPME76tngDlAb1XtCDzCgf1UXwyoq8B91/sck2ngH1tVV+IOgqfjEt0zAdM+VdVJQDdc8d4sEUmrZz1v4YpExuEOJk95n7MProhlGpChqp2Aj2n8+96GO7gGfk+HVL/xyr9vwSW6zt569wSst7Fuh7cAfYLWXYErfmuqS3FJYqP3W5mJK+qZBGwHSqn/9xLyOyTo94K7sg1W8xnD2B8NbevvwDgRORIYArxYz3wHLUsE0ac97lJ5t7iWJXf5vUHvDHcJMF1EkkTkWIIqf4NcCjyOK5/P9V6jgVwRGYYrD75MRE7xKh17ichg76z7VVwC6SwiiSJSneg+AIaKSK531jw9jNDb464wSsU1SbwoYNrTwKki8h0RSfAqVnMDpj8F3Ox9htmNbOcZ4FpcUp5ZPVJELhaRrqpaBez2Rlc2sJ6ncAmjE/CyNy4Nd8Da5q3zMtwVQYNUtRJXbj/du4o8jNqtcdrjDtzbgAQRuROXvKttBXJEpL5jwLPA9eIaEaTjip2eU9WKxmILJCK9gFOAszjwWzkStx8u9fbd48BvRaSnV2l7rHcF1tB3uBx3pZYqrvL8e42E0tj+mAHcIyIDxDlCRDIAVHUzsBh3wvCCqu5ryj44GFgiiD4P4CrgtgP/BV5rpe1+F1fWvwNXLv4crgKwloB/7AdU9auA11Iv1ktV9T3gMuB3uLOuf3Pg7HIyrqx5NfA1cB2Aqn4C3A3Mw7XyCOfGqB8Ad4tIIXAnrjISb30bcc0zb8Q1WVyOOwBVm+3FNFtVixvZzrO4+px/qer2gPFjgRUiUgT8HldGXhpi+WpP4c6sn1PV/V6cK4Hf4K5QtuIS038aiafaNNyZ9le4OpQnAqa9jku6n+CuaEqpXVRSndB2iMiyEOt+HHfgWwSs95b/YZhxBZoMLFfVNwJ/L8CDwBEicjjwY1xF7WLcd/UrXOVsQ9/h73D1LFtxRTdP07DG9sdvcb+fN3D1GX/B/R9W+yvuu2lzxUJwoMWIMbWIyHPAalX1/YokUkTkM+D7qjov0rGY6OZduf4dyPGuYtoUuyIwAIhrX9/fK8oZiyvLfjHCYflGRC7AFcn8K9KxmOgmIom4+x9mtMUkAK4VgDHgKtv+gWs7vRm4WlXfj2xI/hCRhcBhuHsA2uQ/tmkZIjIEV3/2Aa64s02yoiFjjIlxVjRkjDEx7qArGsrMzNScnJxmLVtcXExaWshm3hEVrXFB9MZmcTWNxdU0bTGupUuXblfVriEnRvrW5qa+8vLytLkWLFjQ7GX9FK1xqUZvbBZX01hcTdMW4wKWqHUxYYwxJhRLBMYYE+MsERhjTIyzRGCMMTHOEoExxsQ4SwTGGBPjLBEYY0yMO+huKDPGmLaoskopKq1gb2k5e/aVU+i9LyytYK83HL+7knwftm2JwBhjviFVZX9FFXtLy9m7r+4B3A03NK2Cov2NP/PnzL6JvsTvayLwujP+Pe5B2zNU9ZdB0zvi+vg+xIvlflV9os6KjDHGR1VVSuH+ipqD9eqdlZSv3OodrMvZW1pR90AedEAvq2y4I9uEOKF9SgId2iW6vymJ5GSm0iElsda44Hnc9ATSkxN4+61Fvnx+3xKB97D1h4DTcN0aLxaROeqeyFTtGmClqp7tPch6jYg8raplfsVljGl79ldUsndfRc1BO9SZeOhpbriorII6HTG/t6TWYLvEeDq0O3Cw7pKWRJ+MNDqkJNDeO1gHHsg71BzY3bR2ifGI+Pno8ebz84pgFLBWVdcBiEgB7mEngYlAgfbi9k467nF0TXomqjHm4FZVpRSXVdQ+695XTuH+2gfwwDPyvaUVFO7zDuyl5ZRVNHw2HifUOVgf0iW1Zlz7FO/A7R3A161ZyQlHj6yZ1j4lgcT4ttu2xrfnEYjIeGCsql7hDU8GjlbVaQHztAfmAINxD5e+UFX/GWJdVwFXAWRlZeUVFBQ0K6aioiLS09ObtayfojUuiN7YLK6maa24qlQpKYfCMqWwXN3fMqWoZhj33hsuLquitFJo7CiUFAftEoXUBGiXIKR671O99+0S8P668WnV7xPd/CnxNOlsvC1+j2PGjFmqqiNDTfPziiDUXg/+vr+NeyD1yUB/4E0ReUtV99ZaSPVR4FGAkSNHan5+frMCWrhwIc1d1k/RGhdEb2wWV9M0N659ZZXsLCljZ1GZ+1u8n53F5ewqLmNHcRm7isvYWeym7SouY1dJGVX1HNVTk+LpnJpERnoSh3RJoktaEoU7tnLYoTlBZ+a1i1fapySSlNC6Z+Nt7XtsjJ+JYDPQO2A4G9gSNM9lwC+9LlLXish63NXBez7GZUxMqqxSdpd4B27voF19MK85qJeUs7N4P7uKy9lRvJ/S8tBFLvFxQufURLqkJdE5NYkB3dLpkpZU69U5tfZwSmJ8nfW4A9sgvz+6aYSfiWAxMEBE+gJfABOBi4Lm2QicArwlIlnAIGCdjzEZ0yaoKiVllTUH9eqz9sCDe+C0rbuLKXl9bt0KUU96sqv87JyWRLf2KQzK6kCXtES6pCXTJS2x5ky+c2oSGWnJtE9JIC4uOis+TdP5lghUtUJEpgGv45qPPq6qK0Rkqjf9EeAe4EkR+QhXlHSLqm73KyZjolV5ZRW7SsrYVVwe8uC+szjoVVJWbwVpYrzUOhsf0qMDOe32M2xA3zpn7BnpSXRKTSQ5oe7Zuokdvt5HoKpzgblB4x4JeL8F+JafMRjT2lRdm/RdwQfvgLL0A8Uz5ewo2s/e0voby3Xwmip2SUuiZ6cUhvbsQJf0JLoEHOw7pyWR4f1tn5xQp2LUFcEM9Pujm4OU3VlsTBOpKtuLytiwo5j124pZv6OYDduL+XxHCVt2llD85quUV4Yug0mKj6t1Vp7dOfVAebp3cO+clkhGWjKdvSKZttxs0UQHSwTG1GNXcVnNQX6999qwo5gN20tqdQeQGC/07pJKTkYamfElDD20jzs7D6os7ZKWRGpS9N5UZGKXJQIT0/aWltcc6DdsL3Fn+d7wnn3lNfPFCTUH+5F9upCTkUpOZhr9MtPp2SmFBO+s3RXBDI7UxzGmWSwRmDavpKyizkF+g3d2v73oQG8mItCzYztyMlM5+8ge5GSk0TczjZzMNHp3Tm31tuzGtBZLBKZNKC2vZOPOkloH+XXb3N+te/fXmjerQzI5GWmcOiSLnMw0cjLS6Nc1jUO6pIZs625MW2eJwBw0yiur2LTTndm/uaGceS9+xIbt7uC/Zc++Wm3kM9KSyMlM4/hDu9KvqzvY52S6op20ZPvZGxPI/iNMVKmsUr7YtS9kJe3mXfuoDOi/oEPKFvp2TeeonM7kZGbTN9MV5fTJSKNjO3/6bTemLbJEYFpdVZXy1d7SOuX167cXs3FnSa2ml2lJ8eRkpnF4r46cc2RP78w+jS1rlnPWafnWAseYFmCJwPhCVdlWuL/mbH5d9QHfq7TdH3BXbHJCHH0z0xjQrT2nHdadvl4RTt+uaXRNTw55sC9cL5YEjGkhlghMs6kqO4u9G6u2l7iinB3VB/xiissqa+ZNjBcO6ZJK38w0ThyYSU5mGn29s/vuHVKs3xpjIsgSgWnUnn3ldVriVJffB3aNEB8n9O7cjpzMNI7K6VLT9LJfZho9O7Uj3g72xkQlSwSmjh1F+3lp+RZe+/grVn1RTOFrb9RMq25r3zczjXG5vdyZvVeU07tLqnWHYMxByBKBAVzTzIVrtjFr6Sb+tfpryiuVoT07MCIrgeOGHVpzZt/b2tob0+ZYIohxa74qZOaSTby4/Au2F5WRmZ7MZaP7csGIbAZ1b++6TDipf6TDNMb4yBJBDNpdUsZLy7cwa+lmPvpiD4nxwimDs5gwMpsTB3a14h1jYowlghhRUVnFW59uZ+bSTcxb+TVllVUM7dmBu84+jHG5veiSlhTpEI0xEWKJoI37dGshs5Zu5h/vf8G2wv10SUvi4mP6MD4vm8N6doh0eMaYKGCJoA3aU1LOnA9d0c8Hm3aTECeMGdyN8XnZjBnUzXrRNMbUYomgjaisUt5eu52ZSzbxxsqtlFVUMbh7e+44cwjnDu9FZnpypEM0xkQpSwQHuc+2Fbmin2Wb2bp3P51SE7lo1CGMz8tmaM8O1g2DMaZRlggOQntLy/nnh18yc8kmlm3cTXyckD+wK9PPzubkId1ITrB2/saY8FkiOEhUVSnvfLaDWUs38dqKrygtr2JAt3RuP2Mw5+b2oluHlEiHaIw5SFkiiHIbthfzwrLNvLB0M1v2lNIhJYEJeb0Zn5fNEdkdrejHGPONWSKIQkX7K5j74ZfMXLqJxRt2ESdw4sCu3H7mEE4dkmVdPBhjWpQlgihRVaX8d/0OZi3dzKsffcW+8kr6dU3jlrGDOW94L7p3tKIfY4w/LBFE2KadJcz+tIw7/reAzbv20T45gXOH92LCyGyG9+5kRT/GGN9ZIoiAkrIK5n70FbOWbuK/63YiwPEDOnLTtwfx7aHdrejHGNOqLBG0ElXlvfU7mbV0M3M/+pLiskpyMlK56duD6F66kQtOPzrSIRpjYpSviUBExgK/B+KBGar6y6DpNwHfDYhlCNBVVXf6GVdr2ryrhH8s+4JZSzezcWcJ6ckJnHVETyaMzCavT2dEhIULN0c6TGNMDPMtEYhIPPAQcBqwGVgsInNUdWX1PKp6H3CfN//ZwPVtIQnsK6vktRVfMmvpZt75bAeqcFz/DK47dQBjD+9OapJdiBljooefR6RRwFpVXQcgIgXAOGBlPfNPAp71MR5fqSrLNu5i5pLNvPLhlxTtr6B3l3Zcd8pAzh/Ri95dUiMdojHGhCSq6s+KRcYDY1X1Cm94MnC0qk4LMW8q7qrh0FBXBCJyFXAVQFZWVl5BQUGzYioqKiI9Pb1Zy9ZnZ2kV//migre/qGBriZIcD0d1T+D4XgkM7BxHXBitfvyIq6VEa2wWV9NYXE3TFuMaM2bMUlUdGWqan1cEoY6A9WWds4H/1FcspKqPAo8CjBw5UvPz85sV0MKFC2nusoFKyyt5Y+VWZi7ZxNtrt6MKR/ftwo/zsjljWA/Skpu2W1sqLj9Ea2wWV9NYXE0Ta3H5mQg2A70DhrOBLfXMO5EoLxZSVZZv2s3MpZt5+YMtFJZW0KtTO3548gDGj8jmkAwr+jHGHJz8TASLgQEi0hf4Anewvyh4JhHpCJwEXOxjLM22dW+p1+pnE59tKyYlMY4zDu/B+LxsjumXQVyc3fBljDm4+ZYIVLVCRKYBr+Oajz6uqitEZKo3/RFv1vOAN1S12K9Ymmp/RSXzVn7NzKWbWPTJNqoUjsrpzFUn9uOMYT1on5IY6RCNMabF+NqOUVXnAnODxj0SNPwk8KSfcYRDVfnoiz3MWrqZl5ZvYc++cnp0TOEH+YdyQV42fTPTIh2iMcb4IuYbtH9dWMpL77vn+67ZWkhyQhxjD+/O+LxsjuufSbwV/Rhj2riYTARlFVX8a/VWZi3dzII126isUkYc0omfnzeMM4/oQcd2VvRjjIkdMZUIPt9byfQ5K3hp+RfsKiknq0MyV53YjwtGZHNot+hrM2yMMa0hZhLBzCWbuOudUpLiN3La0Cwm5GVz/KGZJMTHRTo0Y4yJqJhJBGMGd2PyYUncOP4kOqUmRTocY4yJGjFzOpyZnswphyRaEjDGmCAxkwiMMcaEZonAGGNinCUCY4yJcZYIjDEmxlkiMMaYGGeJwBhjYpwlAmOMiXGWCIwxJsZZIjDGmBhnicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMMaYGGeJwBhjYpwlAmOMiXGWCIwxJsZZIjDGmBhnicAYY2Kcr4lARMaKyBoRWSsit9YzT76ILBeRFSLybz/jMcYYU1eCXysWkXjgIeA0YDOwWETmqOrKgHk6AQ8DY1V1o4h08yseY4wxofl5RTAKWKuq61S1DCgAxgXNcxHwD1XdCKCqX/sYjzHGmBBEVf1Zsch43Jn+Fd7wZOBoVZ0WMM8DQCIwFGgP/F5VnwqxrquAqwCysrLyCgoKmhVTUVER6enpzVrWT9EaF0RvbBZX01hcTdMW4xozZsxSVR0ZcqKqNvgCzgLiGpsvxHITgBkBw5OBPwTN80fgv0AakAl8CgxsaL15eXnaXAsWLGj2sn6K1rhUozc2i6tpLK6maYtxAUu0nuNqOEVDE4FPReTXIjKkCQloM9A7YDgb2BJintdUtVhVtwOLgCObsA1jjDHfUKOJQFUvBoYDnwFPiMi7InKViLRvZNHFwAAR6SsiSbiEMidonpeAE0QkQURSgaOBVU3+FMYYY5otrMpiVd0LvICr8O0BnAcsE5EfNrBMBTANeB13cH9eVVeIyFQRmerNswp4DfgQeA9XlPTxN/g8xhhjmqjR5qMicjZwOdAf+BswSlW/9s7gVwF/qG9ZVZ0LzA0a90jQ8H3AfU0P3RhzsBMR1q9fT2lpaaRDqaVjx46sWhV9hRPhxJWSkkJ2djaJiYlhrzec+wgmAL9T1UWBI1W1REQuD3tLxhgTJC0tjfbt25OTk4OIRDqcGoWFhbRv31jpd+trLC5VZceOHWzevJm+ffuGvd5wiobuwhXbACAi7UQkx9vo/LC3ZIwxQeLj48nIyIiqJHAwExEyMjKafIUVTiKYCVQFDFd644wx5huzJNCymrM/w0kECeruDAbAe5/U5C0ZY0yU2bFjB7m5ueTm5tK9e3d69epFbm4uo0ePpqysrMFllyxZwrXXXtvoNo477riWCtc34dQRbBORc1R1DoCIjAO2+xuWMcb4LyMjg+XLlwMwffp00tPT+fGPf0xhYSFJSUlUVFSQkBD6MDly5EhGjgx9o26gd955pyVD9kU4VwRTgdtFZKOIbAJuAb7vb1jGGBMZU6ZM4bbbbmPMmDHccsstvPfeexx33HEMHz6c4447jjVr1gCwcOFCzjrrLMAlkcsvv5z8/Hz69evHgw8+WLO+6i4hFi5cSH5+PuPHj2fw4MF897vfre5hgblz5zJ48GCOP/54rr322pr1tpZGrwhU9TPgGBFJx/VNVOh/WMaYWPPTl1ewcsveFl3nYT07cNfZQ5u83Nq1a5k3bx7x8fHs3buXRYsWkZCQwLx587j99tt54YUX6iyzevVqFixYQGFhIYMGDeLqq6+u04Tz/fffZ8WKFfTs2ZPRo0fzn//8h5EjR/L973+fRYsW0bdvXyZNmtTsz9tcYXVDLSJn4jqGS6muiFDVu32MyxhjIubcc88lPj4egD179nDppZfy6aefIiKUl5eHXObMM88kOTmZ5ORkunXrxtatW8nOzq41z6hRo2rG5ebmsmHDBtLT0+nXr19Nc89Jkybx6KOP+vjp6grnhrJHgFRgDDADGE9Ac1JjjGkJzTlz90taWlrN+5/85CeMGTOG2bNns2HDBvLz80Muk5ycXPM+Pj6eioqKsOapLh6KpHDqCI5T1UuAXar6U+BYancmZ4wxbdaePXvo1asXAE8++WSLr3/w4MGsW7eODRs2APDcc8+1+DYaE04iqL4zoUREegLlQPi3rBljzEHs5ptv5rbbbmP06NFUVla2+PrbtWvHww8/zNixYzn++OPJysqiY8eOLb6dhoRTR/Cy90jJ+4BlgAKP+RmUMca0tunTp9e8Lyw80Cbm2GOP5ZNPPqkZvueeewDIz8+vKSYKXBbg448P9J1ZVFRUZ36AP/7xjzXvx4wZw+rVq1FVrrnmmrCapbakBq8IRCQOmK+qu1X1BaAPMFhV72yV6IwxJgY89thj5ObmMnToUPbs2cP3v9+6LfQbvCJQ1SoR+Q2uXgBV3Q/sb43AjDEmVlx//fVcf/31Edt+OHUEb4jIBWIdghhjTJsUTh3BDbhnCleISCkggKpqB18jM8YY0yrCubM4+jrlNsYY02LCuaHsxFDjgx9UY4wx5uAUTh3BTQGvnwAvA9N9jMkYY1pFfn4+r7/+eq1xDzzwQL0Vt/n5+SxZsgSAM844g927d9eZZ/r06dx///0NbvfFF19k5cqVNcN33nkn8+bNa2L0LafRRKCqZwe8TgMOB7b6H5oxxvhr0qRJFBQU1BpXUFDAhAkTGl127ty5dOrUqVnbDU4Ed999N6eeemqz1tUSwrkiCLYZlwyMMeagNn78eF555RX273et4jds2MCWLVuYOXMmI0eOZOjQodx1110hl83JyWH7dvdolnvvvZdBgwZx6qmn1nRTDe7+gKOOOoojjzySCy64gJKSEt555x3mzJnDTTfdRG5uLp999hlTpkxh1qxZAMyfP5/hw4czbNgwLr/88prYcnJyuPfeexkxYgTDhg1j9erVLbYfwqkj+APubmJwiSMX+KDFIjDGGIDrrgPvITEtJjcXHnig3skZGRmMGjWK1157jXHjxlFQUMCFF17ItGnT6NOnD5WVlZxyyil8+OGHHHHEESHXsXTpUgoKCnj//fepqKhgxIgR5OXlAXD++edz5ZVXAnDHHXfwl7/8hR/+8Iecc845nHXWWYwfP77WukpLS5kyZQrz589n4MCBXHLJJfzpT3/iuuuuq4l32bJlPPzww9x///3MmDHjG+8iCO+KYAmw1Hu9C9yiqhe3yNaNMSbCAouHCgoKmDRpErNnz2bEiBEMHz6cFStW1CrGCfbWW29x3nnnkZqaSocOHTjnnHNqpn388ceccMIJDBs2jKeffpoVK1Y0GMuaNWvo27cvAwcOBODSSy9l0aID7XKq152Xl1fTSV1LCOc+gllAqapWAohIvIikqmpJi0VhjDENnLn76dxzz+WGG25g2bJl7Nu3j86dO/Pggw+ydOlSOnfuzJQpUygtLW1wHfXdbztlyhRefPFFjjzySJ588kkWLlzY4Hoa65K6uhvr+rq5bq5wrgjmA+0ChtsBkaveNsaYFpSenk5+fj6XX345kyZNYu/evaSlpdGxY0e2bt3Kq6++2uDyJ554IrNnz2bfvn0UFhby8ssv10wrLCykR48elJeX8/TTT9eMb9++fa2O7aoNHjyYDRs2sHbtWgD+9re/cdJJJ7XQJ61fOFcEKapaVD2gqkUikupjTMYY06omTZrE+eefT0FBAYMHD+aII45g6NCh9OvXj9GjRze47IgRI7jwwgvJzc2lT58+nHDCCTXT7rnnHo4++mj69OnDsGHDag7+EydO5Morr+TBBx+sqSQGSElJ4YknnmDChAlUVFRw1FFHMXXqVH8+dCBVbfAF/AcYETCcB7zb2HJ+vfLy8rS5FixY0Oxl/RStcalGb2wWV9NEa1zLli2LdAgh7d27N9IhhBRuXCtXrqwzDlii9RxXw7kiuA6YKSJbvOEewIUtn5KMMcZEQjh9DS0WkcHAIFyHc6tVNfTTm4OIyFjg90A8MENVfxk0PR94CVjvjfqHqt4ddvTGGGO+sUYri0XkGiBNVT9W1Y+AdBH5QRjLxQMPAacDhwGTROSwELO+paq53suSgDHGtLJwWg1dqaq7qwdUdRdwZRjLjQLWquo6VS0DCoBxzYrSGNNmaSNNJk3TNGd/hpMI4gIfSuOd6SeFsVwvYFPA8GZvXLBjReQDEXlVRIaGsV5jTBtRWVnJjh07LBm0EFVlx44dpKSkNGk5aewLEJH7gBzgEVxXE1OBjar640aWmwB8W1Wv8IYnA6NU9YcB83QAqtQ1ST0D+L2qDgixrquAqwCysrLygjuJCldRURHp6enNWtZP0RoXRG9sFlfTRGtcJSUldOvWjfj4+EiHUouq1nuTWCSFE1dlZSXFxcV1kuuYMWOWqurIelfc0At31TAVd4fxC8AdwENhLHcs8HrA8G3AbY0sswHIbGgeaz7auqI1NouraSyupmmLcdFA89FwuqGuAv4LrANGAqcAqxpbDlgMDBCRviKSBEwE5gTOICLdq4udRGSUl3R2hLFuY4wxLaTe5qMiMhB38J6EOzg/B6CqY8JZsapWiMg04HVc89HHVXWFiEz1pj8CjAeuFpEKYB8w0ctcxhhjWklD9xGsBt4CzlbVtQAiEvqxPfVQ1bnA3KBxjwS8/yPwx6as0xhjTMtqqGjoAuArYIGIPCYip+BuKDPGGNOG1JsIVHW2ql4IDAYWAtcDWSLyJxH5VivFZ4wxxmfhVBYXq+rTqnoWkA0sB271OzBjjDGto0nPLFbVnar6Z1U92a+AjDHGtK7mPLzeGGNMG2KJwBhjYpwlAmOMiXGWCIwxJsZZIjDGmBhnicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMMaYGGeJwBhjYpwlAmOMiXGWCIwxJsZZIjDGmBhnicAYY2KcJQJjjIlxlgiMMSbGWSIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMMaYGOdrIhCRsSKyRkTWisitDcx3lIhUish4P+MxxhhTl2+JQETigYeA04HDgEkiclg98/0KeN2vWIwxxtTPzyuCUcBaVV2nqmVAATAuxHw/BF4AvvYxFmOMMfUQVfVnxa6YZ6yqXuENTwaOVtVpAfP0Ap4BTgb+AryiqrNCrOsq4CqArKysvIKCgmbFVFRURHp6erOW9VO0xgXRG5vF1TQWV9O0xbjGjBmzVFVHhpyoqr68gAnAjIDhycAfguaZCRzjvX8SGN/YevPy8rS5FixY0Oxl/RStcalGb2wWV9NEXVxVVaobN+rCefMiHUlIUbe/PN8kLmCJ1nNcTWhWagnPZqB3wHA2sCVonpFAgYgAZAJniEiFqr7oY1zGmEj55BMoKHCvVasYecgh8NBDcOaZ4I4DJgL8rCNYDAwQkb4ikgRMBOYEzqCqfVU1R1VzgFnADywJGNPGfP45/PrXMGIEDBoE06dD165w772IKpx9NpxyCrz/fqQjjVm+XRGoaoWITMO1BooHHlfVFSIy1Zv+iF/bNsZE2JdfwsyZ7sz/3XfduKOPht/9DiZMgF69AFg8ahQnrVnjkkNeHkyeDD/7GfTuXf+6TYvzs2gIVZ0LzA0aFzIBqOoUP2Mxxvhs+3b4xz/cwX/hQlCFI4+EX/wCvvMd6NevziKakADXXAMXXww//zn8/vfw/PNw441wyy3Qvn3rf44YZHcWG2Oab88e+Otf4YwzoEcP+P734Ysv4M47YeVKWL4cbr01ZBKopWNH+NWvYPVqOO88uPdeOPRQ+POfoaKiVT5KLLNEYIxpmuJieO45d8Du1g2mTHEH/RtvdOX8q1e7op4hQ5q+7pwceOYZ+N//YOBAmDrVXVXMneuuMIwvLBEYYxq3fz+89BJMmuQO/hMnuoP11Ve7OoD16+GXv4Tc3JZp/TNqFCxa5Iqayspcq6JvfQs++OCbr9vUYYnAGBNaeTm8/jpcdhlkZcG558Kbb8Ill7g6gE2b4IEH4Jhj/Gn6KeKuOlascHUHy5bB8OFw+eWu+Mm0GEsExpgDKivh3/92Z/o9e8LYse6s/Lzz4LXXXGugP/0JTjoJ4uNbJ6akJLj2Wli71hU/Pf20Kza66y4oKmqdGNo4SwTGxDpVV8xz/fVwyCGQnw9PPQWnngovvghbt8ITT8C3vw2JiZGLs3NnuO8+WLXK3Xtw990wYADMmOESmGk2SwTGxCLV2i16jjkGHn7Ylc0XFMDXX8Ozz8K4cZCSEuloa+vX78D9Cf36wZVXurqJ160D4+ayRGBMLAls0TN8ONx/PwweDE8+6Q7+s2fDhRdCWlqkI23cMcfA22+7G9dKSlwx1tix8NFHkY7soGOJwJi2bv16DnnmGXfWPGSIK1Lp0QMeeQS++gpefRUuvdS15T/YiMD48a756m9/C++95z7nlVe6+gwTFksExrRFX3zhunM4+mjo149+jz0Gqamu9c3mzbBggbv5KzMz0pG2jORkV8exdi386EfuJrcBA+CnP3X3PZgGxU4i2LOH1I0bXZtkY9qibdsOtOjp3RtuuME1Af3Vr/jvs8/CO++41jc9e0Y6Uv906eKuDFatgtNPd8VgAwbA449bhXIDYicRvPkmoy69FNq1g/793Y/kRz9yXeC++abrIbGqKtJRGtM0u3cfaNHTowf84AeurH/6dFcfsGwZ3Hwzpd27RzrS1tW/v6s7ePtt1xLqe99zvZ/OmxfpyKKSr53ORZVjjmHV7bczJD7e9Yn+ySfuRxLYDjk52fVvMnBg3VfXrtZfuokORUXw8suu5cxrr7mr3L594eab3R2/w4bZb7Xa6NGuddHzz7sWUqed5k4C77sPhg6NdHRRI3YSQXY2W087jSH5+QfGqbrKsurEUP1atQpeecVdVlfr2NElhAEDaieIAQOgQ4dW/zgmxpSWukrdggKXBPbtc105T5vmDv4jR9rBvz4iriXUuefCH/8I99wDRxwBV1zhKs6zsiIdYcTFTiIIRcRdTvfo4cpVA1VUwMaNdZPEf/7j2lcHdoDVvXvtxFD9vn9/d5VhTHOUl7tiy4ICd2NXYaG7Mr3sMnfwHz0a4mKndPcbS052dyZPmeKSwUMPuQ7ubrnF1aekpkY6woiJ7UTQkIQEd7NKv36ubXKgffvgs89cYvj00wNJYs4cVz5bLS4O+vSpewUxcKArt2ytW/TNwaO6i4eCAnjhBdi5012NTpjgDv5jxrjfpmm+jAzXR9I117gk8JOfuKa0997rHowTg8nVflHN0a4dHH64ewXbvftAcghMEu+8487oqiUl1dRH9EtJcYmlOll062aX+bGkqgr++1938J850xVXpqW5u3onTnS9btqVZcsbMMD1o/TWWweuFB54AH7zm5hLBpYIWlqnTnDUUe4VSNX12RJc1PTJJ2R/+qk7CFRr3z50hfWAAQfnTT+mLlXXd39Bgevbf+NGd7A/80x38D/zzJguqmhVJ5zgEvFzz8Ftt8Epp3D4scfCX/7SvGcqHIQsEbQWEVeX0L07nHhirUmL5s8nv1+/ukmi+iwxsD4iK6tuhXV1fUS09Qlj6lq50n2nBQXuijEhwZ3x/+xn7grAGh5ERlyce9bCeefBgw/S6e67Xeurq65yTXG7dYt0hL6yRBAN4uNd87++fV178EClpbBuXd0k8c9/uptkqom4+ohQSaJPH6uPiKS1a93Z5nPPuX5w4uJcWf/NN7sDT0ZGpCM01VJS4Oab+d/AgYyeP9/doPf3v7srheuuc8XCbZAlgmiXkgKHHeZewfburV0PUf3629/ctGpJSe6KIVTLpu7drT7CD5s2ubbrBQWwZIkbN3o0/OEPrm+cWLvB6yBT3qmT+66mTXMVyrff7pLCz38OF13U5uoQLBEczDp0gLw89wqk6lovBVdYf/KJuwFp//4D86anh27VNHCgq+84GFUXpYXztynzNrZMYSE9Z892rVDeftuNy8tzNy995zuupZg5uAwa5JruLlzoKpQnTz5QoRzc5PwgZomgLRJxdQlZWa4iLFBlpTtbDU4S773nzmADu9no3Jnj4MDDSPw6gDZjmZPqWybCBoK7Y/Wee9xNTAMGRDok0xLy82HxYnffwe23u+FzzoFf/9oli4OcJYJYEx8POTnu9a1v1Z62f3/t+ogNG9i+aRM9e/Y8UHwU+DfUuMb+ttAyGz//nD45Ob5vp0nLxMezOD2doy67DNMGxcXBxRfDBRe4q4Jf/MIl/alT3WMzu3aNdITNZonAHJCc7JrLBTSZ+2ThQnoGdssRJdYvXEifKIyreOHCSIdg/Naunas8/t73XIuiRx5x9XL/93+ud9eDsPVe26rxMMaY1tKtm3u850cfuSbht9zinvb27LMHXU/GlgiMMeabGDLEdQQ4f757HsJFF7nHaL71VqQjC5slAmOMaQknn+yaCj/5JGzZ4q4Szj/fNcqIcr4mAhEZKyJrRGStiNwaYvo4EflQRJaLyBIROd7PeIwxxldxce75z5984lqOvfGGuwfoRz+CHTsiHV29fEsEIhIPPAScDhwGTBKR4Lui5gNHqmoucDkww694jDGm1aSmwh13uLvKL7/cPQehf3+4//7a9/FECT+vCEYBa1V1naqWAQXAuMAZVLVItaYBeBoQHY3BjTGmJXTvDn/+M3z4IRx3HNx0k6tTeP75qLn3BUDUp2BEZDwwVlWv8IYnA0er6rSg+c4DfgF0A85U1XdDrOsq4CqArKysvILAnjqboKioiPT09GYt66dojQuiNzaLq2ksrqbxK67OS5bQ/09/In3dOvYcdhifXX01e0N1Z+9DXGPGjFmqqiNDTlRVX17ABGBGwPBk4A8NzH8iMK+x9ebl5WlzLViwoNnL+ila41KN3tgsrqaxuJrG17gqKlQff1y1Rw937/z48apr1/oeF7BE6zmu+lk0tBnoHTCcDWypb2ZVXQT0F5FMH2MyxpjIio93jxv99FN3Q9rcua646IYb3BPpIsDPRLAYGCAifUUkCZgIzAmcQUQOFXH36IvICCAJiN6qdWOMaSlpaa5rirVr4ZJLXLcVhx4Kv/tdq1co+5YIVLUCmAa8DqwCnlfVFSIyVUSmerNdAHwsIstxLYwu9C5hjDEmNvToATNmwPLl7smGN9zgmpzOmtVqFcq+3kegqnNVdaCq9lfVe71xj6jqI977X6nqUFXNVdVjVfVtP+MxxpiodcQR8Prrrqv41FSYMAGOP949qdBndmexMcZEk29/210dPPaY6w342GPdc6zXr/dtk5YIjDEm2sTHwxVXuArlO++EOXNg8GCyZ870ZXOWCIwxJlqlp8NPf+oSwne/S2mPHr5sxhKBMcZEu1694PHH2X68P92xWSIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMMaYGGeJwBhjYpwlAmOMiXGWCIwxJsb59oQyv4jINuDzZi6eCWxvwXBaSrTGBdEbm8XVNBZX07TFuPqoatdQEw66RPBNiMgSre9RbREUrXFB9MZmcTWNxdU0sRaXFQ0ZY0yMs0RgjDExLtYSwaORDqAe0RoXRG9sFlfTWFxNE1NxxVQdgTHGmLpi7YrAGGNMEEsExhgT49pkIhCRsSKyRkTWisitIaaLiDzoTf9QREZESVz5IrJHRJZ7rztbKa7HReRrEfm4numR2l+NxdXq+0tEeovIAhFZJSIrRORHIeZp9f0VZlyR2F8pIvKeiHzgxfXTEPNEYn+FE1dE/h+9bceLyPsi8kqIaS2/v1S1Tb2AeOAzoB+QBHwAHBY0zxnAq4AAxwD/i5K48oFXIrDPTgRGAB/XM73V91eYcbX6/gJ6ACO89+2BT6Lk9xVOXJHYXwKke+8Tgf8Bx0TB/gonroj8P3rbvgF4JtT2/dhfbfGKYBSwVlXXqWoZUACMC5pnHPCUOv8FOomIPw8DbVpcEaGqi4CdDcwSif0VTlytTlW/VNVl3vtCYBXQK2i2Vt9fYcbV6rx9UOQNJnqv4BYqkdhf4cQVESKSDZwJzKhnlhbfX20xEfQCNgUMb6buP0Q480QiLoBjvcvVV0VkqM8xhSsS+ytcEdtfIpIDDMedTQaK6P5qIC6IwP7yijmWA18Db6pqVOyvMOKCyPy+HgBuBqrqmd7i+6stJgIJMS4404czT0sLZ5vLcP2BHAn8AXjR55jCFYn9FY6I7S8RSQdeAK5T1b3Bk0Ms0ir7q5G4IrK/VLVSVXOBbGCUiBweNEtE9lcYcbX6/hKRs4CvVXVpQ7OFGPeN9ldbTASbgd4Bw9nAlmbM0+pxqere6stVVZ0LJIpIps9xhSMS+6tRkdpfIpKIO9g+rar/CDFLRPZXY3FF+velqruBhcDYoEkR/X3VF1eE9tdo4BwR2YArPj5ZRP4eNE+L76+2mAgWAwNEpK+IJAETgTlB88wBLvFq348B9qjql5GOS0S6i4h470fhvp8dPscVjkjsr0ZFYn952/sLsEpVf1vPbK2+v8KJK0L7q6uIdPLetwNOBVYHzRaJ/dVoXJHYX6p6m6pmq2oO7hjxL1W9OGi2Ft9fCd9k4WikqhUiMg14HddS53FVXSEiU73pjwBzcTXva4ES4LIoiWs8cLWIVAD7gInqNRPwk4g8i2shkSkim4G7cJVnEdtfYcYVif01GpgMfOSVLwPcDhwSEFck9lc4cUVif/UA/ioi8bgD6fOq+kqk/x/DjCsi/4+h+L2/rIsJY4yJcW2xaMgYY0wTWCIwxpgYZ4nAGGNinCUCY4yJcZYIjDEmxlkiMMYjIpVyoKfJ5RKih9hvsO4cqacXVWMirc3dR2DMN7DP63LAmJhiVwTGNEJENojIr8T1X/+eiBzqje8jIvPF9Qk/X0QO8cZnichsr7OyD0TkOG9V8SLymLj+79/w7mhFRK4VkZXeegoi9DFNDLNEYMwB7YKKhi4MmLZXVUcBf8T1Don3/ilVPQJ4GnjQG/8g8G+vs7IRwApv/ADgIVUdCuwGLvDG3woM99Yz1Z+PZkz97M5iYzwiUqSq6SHGbwBOVtV1XsduX6lqhohsB3qoark3/ktVzRSRbUC2qu4PWEcOrqvjAd7wLUCiqv5MRF4DinC9W74Y0E++Ma3CrgiMCY/W876+eULZH/C+kgN1dGcCDwF5wFIRsbo706osERgTngsD/r7rvX8H10MkwHeBt73384GroebhJx3qW6mIxAG9VXUB7mEknYA6VyXG+MnOPIw5oF1Az50Ar6lqdRPSZBH5H+7kaZI37lrgcRG5CdjGgV4gfwQ8KiLfw535Xw3U101wPPB3EemIe+DI77z+8Y1pNVZHYEwjvDqCkaq6PdKxGOMHKxoyxpgYZ1cExhgT4+yKwBhjYpwlAmOMiXGWCIwxJsZZIjDGmBhnicAYY2Lc/wO5bEf0cNv87wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h['accuracy'],label='Training')\n",
    "plt.plot(h['val_accuracy'],c='red',label='Validation')\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d84cdf",
   "metadata": {},
   "source": [
    "## Step 6: GoogLeNet Model\n",
    "\n",
    "Following the keras documentation available from https://keras.io/api/applications/inceptionv3/, we built our GoogLeNet model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6fb3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inceptionv3_model=Sequential()\n",
    "pretrained_model_2=tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\",input_shape=(256,256,3))\n",
    "for layer in pretrained_model_2.layers:\n",
    "    layer.trainable=False\n",
    "Inceptionv3_model.add(pretrained_model_2)\n",
    "Inceptionv3_model.add(Flatten())\n",
    "Inceptionv3_model.add(Dense(14,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "236b9562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Functional)    (None, 6, 6, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                1032206   \n",
      "=================================================================\n",
      "Total params: 22,834,990\n",
      "Trainable params: 1,032,206\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inceptionv3_model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])\n",
    "Inceptionv3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17a28f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model check point\n",
    "mc = ModelCheckpoint(filepath=\"googlenet_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "# puting call back in a list \n",
    "call_back = [es, mc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d205582",
   "metadata": {},
   "source": [
    "### Experimentation of GoogLeNet Model\n",
    "\n",
    "The model was trained only on one epoch and later on five epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "265955bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11446/11446 [==============================] - ETA: 0s - loss: 0.9252 - accuracy: 0.9653 - auc: 0.9846\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52341, saving model to googlenet_model.h5\n",
      "11446/11446 [==============================] - 93973s 8s/step - loss: 0.9252 - accuracy: 0.9653 - auc: 0.9846 - val_loss: 48.2088 - val_accuracy: 0.5234 - val_auc: 0.7513\n"
     ]
    }
   ],
   "source": [
    "hist_2=Inceptionv3_model.fit(x=train_data,validation_data=test_data, epochs=1, callbacks=call_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e13da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 0.8061 - accuracy: 0.9740 - auc: 0.9882\n",
      "Epoch 00001: val_accuracy did not improve from 0.52341\n",
      "11446/11446 [==============================] - 93695s 8s/step - loss: 0.8061 - accuracy: 0.9740 - auc: 0.9882 - val_loss: 53.7490 - val_accuracy: 0.4344 - val_auc: 0.7056\n",
      "Epoch 2/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.9780 - auc: 0.9898\n",
      "Epoch 00002: val_accuracy did not improve from 0.52341\n",
      "11446/11446 [==============================] - 94182s 8s/step - loss: 0.7486 - accuracy: 0.9780 - auc: 0.9898 - val_loss: 68.2289 - val_accuracy: 0.3945 - val_auc: 0.6823\n",
      "Epoch 3/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.9807 - auc: 0.9910\n",
      "Epoch 00003: val_accuracy did not improve from 0.52341\n",
      "11446/11446 [==============================] - 94423s 8s/step - loss: 0.6933 - accuracy: 0.9807 - auc: 0.9910 - val_loss: 65.5159 - val_accuracy: 0.5026 - val_auc: 0.7392\n",
      "Epoch 4/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.9825 - auc: 0.9918\n",
      "Epoch 00004: val_accuracy did not improve from 0.52341\n",
      "11446/11446 [==============================] - 94849s 8s/step - loss: 0.6613 - accuracy: 0.9825 - auc: 0.9918 - val_loss: 73.4466 - val_accuracy: 0.4331 - val_auc: 0.7007\n",
      "Epoch 5/5\n",
      "11446/11446 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.9843 - auc: 0.9926\n",
      "Epoch 00005: val_accuracy did not improve from 0.52341\n",
      "11446/11446 [==============================] - 94929s 8s/step - loss: 0.6211 - accuracy: 0.9843 - auc: 0.9926 - val_loss: 97.0456 - val_accuracy: 0.3911 - val_auc: 0.6784\n"
     ]
    }
   ],
   "source": [
    "hist_2=Inceptionv3_model.fit(x=train_data,validation_data=test_data, epochs=5, callbacks=call_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98230332",
   "metadata": {},
   "source": [
    "### Loading the best fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00a725c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model_2=load_model(\"googlenet_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb83758",
   "metadata": {},
   "source": [
    "### GoogLeNet Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b830d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1740/1740 [==============================] - 8965s 5s/step - loss: 48.2087 - accuracy: 0.5234 - auc_2: 0.7513\n",
      "The accuracy of GoogLeNet model is =52.34125256538391%\n"
     ]
    }
   ],
   "source": [
    "acc=model_2.evaluate_generator(generator=test_data,steps=len(test_data),verbose=1)[1]\n",
    "print(f\"The accuracy of GoogLeNet model is ={acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00a410ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'auc', 'val_loss', 'val_accuracy', 'val_auc'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2=hist_2.history\n",
    "h2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b963a59",
   "metadata": {},
   "source": [
    "### GoogLeNet model plot against training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fdf295d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h2['accuracy'],label='Training')\n",
    "plt.plot(h2['val_accuracy'],c='red',label='Validation')\n",
    "plt.title('Training Accuracy vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f68dea8",
   "metadata": {},
   "source": [
    "## Step 7: Vision Transformer\n",
    "\n",
    "The following documentation of the model was followed from \n",
    "\n",
    "https://huggingface.co/docs/transformers/model_doc/vit#transformers.TFViTForImageClassification\n",
    "\n",
    "https://huggingface.co/docs/transformers/training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9a93",
   "metadata": {},
   "source": [
    "### Installling necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9296027d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896de62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96be2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-transformers\n",
      "  Using cached pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
      "Collecting torch>=1.0.0\n",
      "  Downloading torch-1.12.1-cp39-cp39-win_amd64.whl (161.8 MB)\n",
      "Requirement already satisfied: boto3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-transformers) (1.21.32)\n",
      "Requirement already satisfied: regex in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2022.3.15)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53.tar.gz (880 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-transformers) (1.21.5)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from pytorch-transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.0.0->pytorch-transformers) (4.1.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers) (0.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch-transformers) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3->pytorch-transformers) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.32->boto3->pytorch-transformers) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->pytorch-transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->sacremoses->pytorch-transformers) (0.4.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=c415ea492044a4d13783c6f7dea922ef83fe8ca93961a234556d2b60e0cdf89d\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\12\\1c\\3d\\46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: torch, sentencepiece, sacremoses, pytorch-transformers\n",
      "Successfully installed pytorch-transformers-1.2.0 sacremoses-0.0.53 sentencepiece-0.1.97 torch-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a15c151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.27.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (4.64.0)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (1.4.2)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp39-cp39-win_amd64.whl (19.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: dill, xxhash, responses, pyarrow, multiprocess, datasets\n",
      "Successfully installed datasets-2.4.0 dill-0.3.5.1 multiprocess-0.70.13 pyarrow-9.0.0 responses-0.18.0 xxhash-3.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85735c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.13.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (1.21.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4d7a5",
   "metadata": {},
   "source": [
    "### Importing libraries related to Vision Transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f709804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from huggingface_hub import notebook_login\n",
    "#Created an account on hugging face and the notebook.login code is to access and can be done by copying the access code available from hugging face\n",
    "from transformers import TFViTForImageClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard as TensorboardCallback, EarlyStopping\n",
    "from datetime import datetime\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c537f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#The following code cell was executed before the import statements to avoid error and can be seen as the first cell in this notebook. \n",
    "#install Git-LFS to upload your model checkpoints. For large data\n",
    "'''\n",
    "%%capture\n",
    "!sudo apt -qq install git-lfs\n",
    "!git config --global credential.helper store\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b8f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\User/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "#Sign up in hugging face and copy token\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2a6ba",
   "metadata": {},
   "source": [
    "### Importing data into Hugging Face hub and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c8fc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c0ffcdf7df49a797651fa4658db153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/472116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-87092f773d6ae028\n",
      "Reusing dataset imagefolder (C:\\Users\\User\\.cache\\huggingface\\datasets\\imagefolder\\default-87092f773d6ae028\\0.0.0\\0fc50c79b681877cc46b23245a6ef5333d036f48db40d53765a68034bc48faff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350f2451eac04f839bd860bfb6dbef2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"imagefolder\", data_dir=r\"E:\\DATASETS\\UCF Crime\\UCF Crime\")\n",
    "ds = ds['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f745f1c9",
   "metadata": {},
   "source": [
    "## Step 3: Splitting images to 80% train and 20% test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90e91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds.train_test_split(test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "956d9637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Structure:\n",
      "Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 472116\n",
      "})\n",
      "Dataset Labels: Abuse, Arrest, Arson, Assault, Burglary, Explosion, Fighting, NormalVideos, RoadAccidents, Robbery, Shooting, Shoplifting, Stealing, Vandalism\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset Structure:\\n{ds}\",)\n",
    "print(f\"Dataset Labels: {', '.join(data['train'].features['label'].names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ddaafb",
   "metadata": {},
   "source": [
    "#### create an id2label dictionary to decode them back to strings and see what they are. The inverse label2id will be useful too, when we load the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a44241",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ddd32b",
   "metadata": {},
   "source": [
    "## Step 4: Data Pre-processing\n",
    "\n",
    "https://github.com/google-research/vision_transformer/blob/main/vit_jax/input_pipeline.py\n",
    "\n",
    "The path shows that images are to be rescaled or resizedto the resolution (224,224). The model was pretrained on ImageNet-21k  dataset which consists of 14 million images and more than 21000 classes. Thefeature extractor takes the images and convert them to numbers to feed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd2511c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing TFViTForImageClassification: ['vit/pooler/dense/bias:0', 'vit/pooler/dense/kernel:0']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_3_path='google/vit-base-patch16-224-in21k'\n",
    "feature_extractor_3 = ViTFeatureExtractor.from_pretrained(model_3_path)\n",
    "model_3 = TFViTForImageClassification.from_pretrained(model_3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e77cfa",
   "metadata": {},
   "source": [
    "torchvision.transforms usefor the image transformations/data augmentation https://pytorch.org/vision/stable/transforms.html#transforms-on-torch-tensor-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18907982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor_3.image_mean, std=feature_extractor_3.image_std)\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor_3.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor_3.size),\n",
    "            CenterCrop(feature_extractor_3.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b630d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = data['train']\n",
    "val_ds = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04238b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ecbdb",
   "metadata": {},
   "source": [
    "## Step 5: Vision Transformer (ViT) ModelTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "644af284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/vit-base-patch16-224/resolve/main/config.json from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\6b03b61d64598274e01717c40e8909f9e70531219a281e8163bd5b3af5c92d1a.c41e6c561c79e9b15e74a5cc284a31cba59cb1a9e209933c1a04a46ba2e20e44\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Abuse\",\n",
      "    \"1\": \"Arrest\",\n",
      "    \"10\": \"Shooting\",\n",
      "    \"11\": \"Shoplifting\",\n",
      "    \"12\": \"Stealing\",\n",
      "    \"13\": \"Vandalism\",\n",
      "    \"2\": \"Arson\",\n",
      "    \"3\": \"Assault\",\n",
      "    \"4\": \"Burglary\",\n",
      "    \"5\": \"Explosion\",\n",
      "    \"6\": \"Fighting\",\n",
      "    \"7\": \"NormalVideos\",\n",
      "    \"8\": \"RoadAccidents\",\n",
      "    \"9\": \"Robbery\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Abuse\": \"0\",\n",
      "    \"Arrest\": \"1\",\n",
      "    \"Arson\": \"2\",\n",
      "    \"Assault\": \"3\",\n",
      "    \"Burglary\": \"4\",\n",
      "    \"Explosion\": \"5\",\n",
      "    \"Fighting\": \"6\",\n",
      "    \"NormalVideos\": \"7\",\n",
      "    \"RoadAccidents\": \"8\",\n",
      "    \"Robbery\": \"9\",\n",
      "    \"Shooting\": \"10\",\n",
      "    \"Shoplifting\": \"11\",\n",
      "    \"Stealing\": \"12\",\n",
      "    \"Vandalism\": \"13\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.21.1\"\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/vit-base-patch16-224/resolve/main/pytorch_model.bin from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\2be66f502a86da34ba6c947f2c61e33e326b5ab34ee2213d634f6e7da1cafb69.2d858f78fc06693c373c41438a7379c6bc50f2c874d348ee505d8550393a5a88\n",
      "All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([14, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([14]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_3_path='google/vit-base-patch16-224'\n",
    "model_3 = ViTForImageClassification.from_pretrained(\n",
    "    model_3_path, \n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)},ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf605431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/vit-base-patch16-224/resolve/main/config.json from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\6b03b61d64598274e01717c40e8909f9e70531219a281e8163bd5b3af5c92d1a.c41e6c561c79e9b15e74a5cc284a31cba59cb1a9e209933c1a04a46ba2e20e44\n",
      "Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Abuse\",\n",
      "    \"1\": \"Arrest\",\n",
      "    \"10\": \"Shooting\",\n",
      "    \"11\": \"Shoplifting\",\n",
      "    \"12\": \"Stealing\",\n",
      "    \"13\": \"Vandalism\",\n",
      "    \"2\": \"Arson\",\n",
      "    \"3\": \"Assault\",\n",
      "    \"4\": \"Burglary\",\n",
      "    \"5\": \"Explosion\",\n",
      "    \"6\": \"Fighting\",\n",
      "    \"7\": \"NormalVideos\",\n",
      "    \"8\": \"RoadAccidents\",\n",
      "    \"9\": \"Robbery\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Abuse\": \"0\",\n",
      "    \"Arrest\": \"1\",\n",
      "    \"Arson\": \"2\",\n",
      "    \"Assault\": \"3\",\n",
      "    \"Burglary\": \"4\",\n",
      "    \"Explosion\": \"5\",\n",
      "    \"Fighting\": \"6\",\n",
      "    \"NormalVideos\": \"7\",\n",
      "    \"RoadAccidents\": \"8\",\n",
      "    \"Robbery\": \"9\",\n",
      "    \"Shooting\": \"10\",\n",
      "    \"Shoplifting\": \"11\",\n",
      "    \"Stealing\": \"12\",\n",
      "    \"Vandalism\": \"13\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.21.1\"\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/vit-base-patch16-224/resolve/main/tf_model.h5 from cache at C:\\Users\\User/.cache\\huggingface\\transformers\\68692de5d639281cf773cbec64d4513e4393b8331b53f62c3a403eaf388b8d3b.1b0ecc348295de47cb0bdb212e73f611e73b8378d2f1aad712ba52f1461ec099.h5\n",
      "All model checkpoint layers were used when initializing TFViTForImageClassification.\n",
      "\n",
      "Some weights of TFViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier/kernel:0: found shape (768, 1000) in the checkpoint and (768, 14) in the model instantiated\n",
      "- classifier/bias:0: found shape (1000,) in the checkpoint and (14,) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_3_path='google/vit-base-patch16-224'\n",
    "model_3 = TFViTForImageClassification.from_pretrained(\n",
    "    model_3_path, \n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)},ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac31fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reseting model to original weights\n",
      "Freezing VIT layer\n",
      "Model: \"tf_vi_t_for_image_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vit (TFViTMainLayer)        multiple                  85798656  \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  10766     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,809,422\n",
      "Trainable params: 10,766\n",
      "Non-trainable params: 85,798,656\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer_selection = \"Adam\"\n",
    "learning_rate = 0.01 \n",
    "num_of_epochs = 5\n",
    "early_stopper_epochs_patience = 3 \n",
    "freeze_vit_layer = True \n",
    "reset_model = True \n",
    "load_weights_by_name = \"\" \n",
    "og_weights = model_3.get_weights()\n",
    "if reset_model:\n",
    "    print(\"Reseting model to original weights\")\n",
    "    tf.keras.backend.clear_session()\n",
    "    model_3.set_weights(og_weights)\n",
    "\n",
    "if load_weights_by_name:\n",
    "    print(f\"Loading weights {load_weights_by_name}\")\n",
    "    model_3.load_weights(f\"/content/model_weights/{load_weights_by_name}\")\n",
    "\n",
    "for layer in model_3.layers:\n",
    "    if layer.name == \"vit\":\n",
    "        if freeze_vit_layer:\n",
    "            print(\"Freezing VIT layer\")\n",
    "            layer.trainable=False\n",
    "        else:\n",
    "            print(\"Fine-tuning the whole model\")\n",
    "            layer.trainable=True\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model_3.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.AUC()],\n",
    "              )\n",
    "\n",
    "print(model_3.summary())\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a07a1c0",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "641e2d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    'UCF_Crime',\n",
    "  per_device_train_batch_size=32,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=1,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=2e-4,\n",
    "  save_total_limit=2,\n",
    "  remove_unused_columns=False,\n",
    "  push_to_hub=True,\n",
    "  report_to='tensorboard',\n",
    "  load_best_model_at_end=True,\n",
    "  hub_strategy=\"end\"\n",
    ")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "654d082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "005774c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003c125f24d043a6b8fca1c2bc31085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c360c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fd695",
   "metadata": {},
   "source": [
    "###  TrainingArguments, which is a class that contains all the attributes to customize the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8378100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Heriot Watt\\F21MP\\UCF_Crime is already a clone of https://huggingface.co/csr2000/UCF_Crime. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_3,\n",
    "    training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=feature_extractor_3,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974509ae",
   "metadata": {},
   "source": [
    "#### The model could only be trained for 100 steps and one epoch. Kernal was purposely interrupted and  The model evaluation was not conducted due to time constraints and is mentioned in the thesis as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "541e8090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 377692\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 11803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='11803' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  113/11803 14:36:01 < 1537:38:35, 0.00 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.102800</td>\n",
       "      <td>0.831629</td>\n",
       "      <td>0.753389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 94424\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to UCF_Crime\\checkpoint-100\n",
      "Configuration saved in UCF_Crime\\checkpoint-100\\config.json\n",
      "Model weights saved in UCF_Crime\\checkpoint-100\\pytorch_model.bin\n",
      "Feature extractor saved in UCF_Crime\\checkpoint-100\\preprocessor_config.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# rest is optional but nice to have\u001b[39;00m\n\u001b[0;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1498\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1495\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1497\u001b[0m )\n\u001b[1;32m-> 1498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:1740\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1740\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1743\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1744\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1746\u001b[0m ):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1748\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py:2488\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2486\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m   2487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2488\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9162e9",
   "metadata": {},
   "source": [
    "###  evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
